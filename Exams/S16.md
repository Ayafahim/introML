
## 1) Which histograms x1, x2, x3, x4 match which boxplots?


## 2) PCA - 

```python
import numpy as np  
  
# Singular values from the matrix S  
singular_values = np.array([149, 118, 53, 42, 3])  
  
# Square the singular values to get the variances  
variances = singular_values**2  
  
# Total variance is the sum of individual variances  
total_variance = np.sum(variances)  
  
# Proportion of variance explained by each principal component  
proportion_variance_explained = variances / total_variance  
  
# Compute cumulative variance explained by the first two and three principal components  
cumulative_variance_two = np.sum(proportion_variance_explained[:2])  
cumulative_variance_three = np.sum(proportion_variance_explained[:3])  
  
# Print the results  
print("Proportion of variance explained by each component:", proportion_variance_explained)  
print("Cumulative variance explained by the first two components:", cumulative_variance_two)  
print("Cumulative variance explained by the first three components:", cumulative_variance_three)  
  
# Check the statements given in the problem  
A = np.sum(proportion_variance_explained[-3:]) < 0.10  
B = proportion_variance_explained[0] > 0.60  
C = np.sum(proportion_variance_explained[-2:]) < 0.04  
D = cumulative_variance_two > 0.85  
  
# Print the truth value of each statement  
print("Statement A is", A)  
print("Statement B is", B)  
print("Statement C is", C)  
print("Statement D is", D)  
  
# Identify the correct statement  
statements = [A, B, C, D]  
statement_labels = ['A', 'B', 'C', 'D']  
for i, statement in enumerate(statements):  
    if statement:  
        print(f"The correct statement is: {statement_labels[i]}")
```


## 3) plot of each observation plotted onto the two first principal directions given in Equation...Which of the following statements best describes the development of  the measurements? 

Info from last 2 problems:
![[Screenshot 2024-04-18 at 17.30.27.png]]
![[Screenshot 2024-04-18 at 17.30.42.png]]


![[Pasted image 20240418173502.png]]

The matrix `S` is a diagonal matrix containing the singular values of the PCA, and the matrix `V` contains the principal directions (eigenvectors). We have to only look at the mesaurements from start to end which goes from 1 to -3 on the y-axis. The operation `-3v2 - 1v2` is linear combination of the second column of the `V` matrix, which corresponds to the second principal component. 



```python
import numpy as np  
  
# V matrix from the second image  
V = np.array([  
    [-0.3, -0.5,  0.7,  0.2,  0.2],  
    [-0.4,  0.6, -0.0,  0.2,  0.7],  
    [-0.4, -0.4, -0.7,  0.4, -0.0],  
    [-0.6, -0.1, -0.1, -0.8,  0.1],  
    [-0.5,  0.4,  0.2,  0.2, -0.7]  
])  
  
# Extracting the second principal component (v2)  
v2 = V[:, 1]  # This is the second column of V  
  
# Computing -3v2 - 1v2  
result_vector = -3 * v2 - 1 * v2  
  
# Display the result  
print(result_vector)
```
